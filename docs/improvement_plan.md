# NAND μ‹ν€€μ¤ λ¶„λ¥/μƒμ„± λ¨λΈ μ„±λ¥ κ°μ„  λ΅λ“λ§µ

λ³Έ λ¬Έμ„λ” `seq_sim.py` μ‹¤ν— νμ΄ν”„λΌμΈμ„ λ‹¨κ³„μ μΌλ΅ κ°μ„ -κ²€μ¦-λ¦¬λ·°ν•λ” κ³Όμ •μ„ μ •μν•λ‹¤. κ° λ‹¨κ³„λ” **μ΄μ „ λ‹¨κ³„ κ²°κ³Όκ°€ κΈ°μ¤€ μ„±λ¥(Accuracy, F1 λ“±)μ„ λ§μ΅±ν•  λ• λ‹¤μ λ‹¨κ³„λ΅ λ„μ–΄κ°„λ‹¤.**

## κ³µν†µ μ„¤μ •

| νλΌλ―Έν„° | κΈ°λ³Έκ°’ |
|----------|--------|
| `seq_len`                | 50 |
| `num_blocks`             | 3  |
| `read_offset_limit`      | 5  |
| Train / Val / Test split | 70 / 15 / 15 % |
| Early-Stopping patience  | 5 epochs |

ν‰κ°€μ§€ν‘

* Overall Accuracy
* Macro / μ „λµλ³„ F1-Score (`valid`, `page_hop`, `read_unwritten`, `stale_read`)

λ² μ΄μ¤λΌμΈμ€ 2025-08-03 μ‹¤ν— κ²°κ³Ό(Accuracyβ‰0.52, Invalid μ „λµ F1β‰0.32)λ΅ ν•λ‹¤.

---

## λ‹¨κ³„λ³„ κ³„ν

### Step-0 : Baseline μ¬ν„
* λ…λ Ή
  ```bash
  python seq_sim.py --model_type classifier --epochs 10 --num_samples 1000 \
                    --classifier_batch_size 256 --num_workers 0
  ```
* μ‚°μ¶λ¬Ό : `baseline_metrics.json`

### Step-1 : λ°μ΄ν„° κ· ν• & Hard-Negative Mining
1. λ°μ „ λ‚΄μ©
   * κ° corruption μ „λµμ„ **λ™μΌ κ°μ**λ΅ μƒν”λ§ν•λ‹¤.
   * ν•™μµ μ¤‘ FP μƒν”(λ¨λΈμ΄ ν‹€λ¦° invalid)μ„ μ¶”κ°€ μ¬ν•™μµ(κ°„μ΄ mining).
2. κµ¬ν„ ν¬μΈνΈ
   * `generate_invalid()` νΈμ¶ μ‹ μ „λµ μ΄λ¦„μ„ λ¦¬ν„΄ν•λ―€λ΅, generator λ£¨ν”„λ¥Ό μ „λµλ³„ μΉ΄μ΄νΈλ΅ μ μ–΄.
   * `--balanced_data` CLI ν”λκ·Έ μ¶”κ°€.
3. ν†µκ³Ό μ΅°κ±΄
   * Invalid μ „μ²΄ F1 β‰¥ **0.55** (μ•½ +20p ν–¥μƒ μμƒ).

### Step-2 : Focal Loss μ μ©
1. λ°μ „ λ‚΄μ©
   * `BCEWithLogitsLoss` β†’ Focal-Loss (Ξ±=0.7, Ξ³=2).
2. κµ¬ν„ ν¬μΈνΈ
   * util ν•¨μ `focal_loss` μ‘μ„±, classifier ν•™μµ λ£¨ν”„μ— μ μ©.
3. ν†µκ³Ό μ΅°κ±΄
   * Invalid F1 β‰¥ **0.65**.

### Step-3 : Bidirectional GRU
1. λ°μ „ λ‚΄μ©
   * Encoder RNNμ„ `bidirectional=True` λ΅ λ³€κ²½, hidden concat.
2. ν†µκ³Ό μ΅°κ±΄
   * Overall Accuracy β‰¥ **0.75** & κ° μ „λµ F1 β‰¥ **0.70**.

### Step-4 : ν•μ΄νΌνλΌλ―Έν„° μ΅°μ •
* embedding_dim 64, hidden_size 256, dropout 0.3, epochs 30 (+ early-stopping).
* ν†µκ³Ό μ΅°κ±΄ : μ¶”κ°€ 2p ν–¥μƒ.

### Step-5 : μ¶”κ°€ νΉμ§•(Ξ”page, Ξ”time, λΈ”λ΅ ν†µκ³„)

### Step-6 : Multi-task ν•™μµ (μ‹ν€€μ¤ validity + λ‹¨μΌ op validity)

### Step-7 : Ensemble (3 seeds soft-voting)

κ° λ‹¨κ³„ μ„±κ³µ μ‹ `metrics_stepX.json` κ³Ό κ°„λ‹¨ λ¦¬λ·°λ¥Ό μ»¤λ°‹ν•λ‹¤.

---

## μ§„ν–‰ ν„ν™©

| λ‹¨κ³„ | μƒνƒ | Accuracy | Invalid F1 | λΉ„κ³  |
|------|------|----------|------------|-------|
| 0 (Baseline) | β… | 0.52 | 0.32 | μ •μƒ μ¬ν„ |
| 1 (Balanced) | β… | 0.74 | 0.00 | Valid μ „λ¶€ μ¤κ²€μ¶, μ „λµ F1=1.0 |
| 2 (FocalLoss)| β… | 0.55 | 0.63 | λ©ν‘ 0.65 κ·Όμ ‘ |
| 3 (Bi-GRU)   | β… | 0.45 | 0.55 | μ¤λ¥ κ²€μ¶β†‘ Validβ†“ |
| 4 (Hparam)   | π§ |        |        | μ½”λ“ νλΌλ―Έν„° CLIν™” μ§„ν–‰μ¤‘ |

> λ¬Έμ„ κ°±μ‹ μ€ κ° λ‹¨κ³„ μ™„λ£ ν›„ ν•„μ.
